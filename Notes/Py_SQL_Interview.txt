string - 60
list - 80
tuple & set - all
dictionary - 20
claas/function/object - 20
try and exception handling -10
file input/op read write - all
lambda and decorator - 20
pandas - all

-----------------------------------------------------------------------------------------------------------------------
### Python Basics and Data Types

1. *What is Python?*
--> Python is programming language and also folllows the oops concept.
Some feature of python as below : 
1.Object oriented
2.Easy to understand
3.Interpreted language
4.Simple syntax
5.Embedded
6.Huge library
7.Portable
8.Platform independent

2. *What are data types in Python?*
-->
1.None
2.Numeric - int,byte,complex
3.Sequence - List,Tuple,Set,Range,Bytearray,String
4.Boolean

3. *What is the use of data types in Python?*
-->
It represent the type of data stored in variables

4. *How to create all data types in Python?*
-->
num = 43
decimal = 3.4
complex = 3+4j
str='Python'
list = [12,3,42]
set = {1,2,4,5}
tuple = (1,2,3,4)

5. *What is a compiler and interpreter in Python?*
--> Compiler convert the bytecode into sourcecode before execution of code.
	Interpreter execute the code line by line.

### Collections in Python

6. *How to create a list, tuple, set, and dictionary in Python?*
--> List :
my_list = [12,13,14,15,16]
print(my_list)

my_tuple = (12,13,14,15)
print(mu_tuple)

set = {10,11,12}
print(set)

my_dict = {'name':'john,'age':22}
print(my_dict)

7. *What is the difference between a list, tuple, set, and dictionary?*
-->
List : 
A list is an ordered collection of elements.
It is mutable, meaning you can add, remove, or change items after the list is created.
It allows duplicate values and supports indexing and slicing.

Tuple : 
A tuple is also an ordered collection, similar to a list, but it is immutable â€” you cannot change its elements after creation.
Tuples allow duplicates and support indexing.

Set : 
A set is an unordered collection of unique items.
It is mutable, but you cannot access items by index since the elements are unordered.
Duplicates are automatically removed.

8. *When should we use a list, tuple, set, or dictionary?*
--> 
List : 
When we want to add, remove, or change elements frequently.

Tuple : 
You want to protect data from modification.
A group of values that logically belong together and won't change.

Set : 
No duplicates.

Dictionary : 
Each key must be unique, values can be duplicated.

9. *What operations can we perform on lists, tuples, sets, and dictionaries?*

### String and List Operations
s = "Hello World"
| Operation            | Example                      | Output               |
| -------------------- | ---------------------------- | -------------------- |
| Access by index      | `s[0]`                       | `'H'`                |
| Length               | `len(s)`                     | `11`                 |
| Slicing              | `s[0:5]`                     | `'Hello'`            |
| Convert to lowercase | `s.lower()`                  | `'hello world'`      |
| Convert to uppercase | `s.upper()`                  | `'HELLO WORLD'`      |
| Replace              | `s.replace("World", "GPT")`  | `'Hello GPT'`        |
| Split into list      | `s.split()`                  | `['Hello', 'World']` |
| Join list to string  | `' '.join(['Hello', 'GPT'])` | `'Hello GPT'`        |
| Strip spaces         | `'  hello  '.strip()`        | `'hello'`            |
| Check substring      | `'World' in s`               | `True`               |

List operation : 
lst = [1, 2, 3, 4]
| Operation             | Example             | Output                   |
| --------------------- | ------------------- | ------------------------ |
| Access by index       | `lst[0]`            | `1`                      |
| Length                | `len(lst)`          | `4`                      |
| Slicing               | `lst[1:3]`          | `[2, 3]`                 |
| Append                | `lst.append(5)`     | `[1, 2, 3, 4, 5]`        |
| Insert at index       | `lst.insert(1, 10)` | `[1, 10, 2, 3, 4]`       |
| Remove by value       | `lst.remove(3)`     | `[1, 2, 4]`              |
| Delete by index       | `del lst[1]`        | `[1, 3, 4]`              |
| Pop (last by default) | `lst.pop()`         | Removes and returns last |
| Sort ascending        | `lst.sort()`        | Changes list in-place    |
| Reverse               | `lst.reverse()`     | Reverses in-place        |




10. *What is slicing in Python?*
-->
Slicing in python means extracting a portion of a sequence like a string,list or tuple
using a specific start:stop:step

Negative indices work too: -1 is the last element, -2 is second-last, etc.
Slicing does not modify the original object (unless you assign to a slice in a list).
Works on any sequence type: str, list, tuple, etc.

11. **What is the use of the split() method in Python?**
-->
The split() method in Python is used to break a string into a list of substrings, based on a delimiter (separator). It's one of the most commonly used string methods.
string.split(separator, maxsplit)

12. *How to find even and odd numbers from a list?*
numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

even_numbers = []
odd_numbers = []

for num in numbers:
    if num % 2 == 0:
        even_numbers.append(num)
    else:
        odd_numbers.append(num)

print("Even numbers:", even_numbers)
print("Odd numbers:", odd_numbers)

13. *How to find the minimum and maximum elements from a list?*
numbers = [10, 25, 7, 98, 3, 56]

minimum = min(numbers)
maximum = max(numbers)

print("Minimum:", minimum)
print("Maximum:", maximum)


14. *How to find duplicate elements in a list?*
numbers = [1, 2, 3, 4, 2, 3, 5, 6, 1]
duplicates = set()
seen = set()

for num in numbers:
    if num in seen:
        duplicates.add(num)
    else:
        seen.add(num)

print("Duplicate elements:", duplicates)


15. *How to check if a number is prime?*
def is_prime(n):
    if n <= 1:
        return False  # 0 and 1 are not prime
    for i in range(2, int(n**0.5) + 1):
        if n % i == 0:
            return False
    return True


16. *How to create a Fibonacci series in Python?*
# Print first 'n' Fibonacci numbers
def fibonacci_series(n):
    a, b = 0, 1
    for _ in range(n):
        print(a, end=" ")
        a, b = b, a + b

# Example usage
fibonacci_series(10)


17. *How to find the sum of all elements in a list?*
numbers = [10, 20, 30, 40, 50]
total = 0
for num in numbers:
    total += num
print("Sum:", total)



18. *How to reverse a list?*
numbers = [1, 2, 3, 4, 5]
numbers.reverse()
print(numbers)



### Control Flow and Exception Handling

19. **What is the use of if, while, and for statements in Python?**
20. **What is the use of try and except in Python?**
21. **What is the use of pass, break, and continue in Python?**

### Functions and Advanced Concepts

22. *What is a lambda function in Python?*
-->
A lambda function is a small anonymous function. A lambda function can take any number of arguments, but can only have one expression.
x = lambda a,b : a*b
print(x(3,4))

23. *What is a decorator in Python?*
-->
A decorator is a function that takes another function as an argument, adds some functionality, and returns a new function. This allows you to "wrap" another function to extend its behavior (adding some functionality before or after) without modifying the original function's source code.
# A simple decorator function
def decorator(func):
  
    def wrapper():
        print("Before calling the function.")
        func()
        print("After calling the function.")
    return wrapper

# Applying the decorator to a function
@decorator

def greet():
    print("Hello, World!")

greet()

24. *What are classes, objects, and functions in Python?*
-->
Class : A class in Python is a user-defined template for creating objects. It bundles data and functions together, making it easier to manage and use them. 
Object : It is blueprint of class and it has state and behaviour
function : It is reusable block of code that perform specific task

25. *What are the basic Object-Oriented Programming (OOP) concepts?*
-->
Main principles of OOPs in Python are abstraction, encapsulation, inheritance, and polymorphism.
Abstraction : Hiding implementation details of object from user.While still providing easy to use interface.
Encapsulartion : Combining data and methods within a class to protect data from external inference.
Inheritance : Inheritance is a way to create new classes based on existing ones, allowing the new classes to inherit the attributes and methods of the parent class
Polymorphism : allows you to treat objects of different classes as if they were of the same class. Consequently, you can write generic code that works with a variety of objects.

### File Handling and Variables

26. *How to read a file in Python?*
-->
# Read entire file
with open("JVM\first.csv","r")
    content = file.read()
    print(content)

or
# Read file line by line
with open("JVM\first.csv","r") as file:
    for line in file:
    print(line.strip())

27. *What are local and global variables in Python?*
-->
Local - Defined within the function and acsessed within that function
Global - Defined outside the function and accessed in the entire code


### Pandas Library

28. *What is Pandas in Python?*
-->
It is open-source Python library which is used for data manipulation and analysis.

29. *How to create a DataFrame in Pandas?*
--> By using core function like - pd.DataFrame()
Ex - 
import pandas as pd
data =  {'Name': ['Alice', 'Bob', 'Charlie'],
        'Age': [25, 30, 35],
        'City': ['New York', 'London', 'Paris']}
df = pd.DataFrame(data)
print(df)

30. *What SQL operations can be performed on a Pandas DataFrame?*
-->
| **SQL Operation** | **Pandas Equivalent**   |
| ----------------- | ----------------------- |
| `SELECT`          | `df[["col1", "col2"]]`  |
| `WHERE`           | `df[df["col"] > x]`     |
| `GROUP BY`        | `df.groupby(...).agg()` |
| `JOIN`            | `pd.merge()`            |
| `UNION`           | `pd.concat()`           |
| `ORDER BY`        | `df.sort_values()`      |
| `IN` / `NOT IN`   | `isin()` / `~isin()`    |
| `IS NULL`         | `isnull()`              |
| `UPDATE`          | `df.loc[...] = ...`     |
| `DELETE`          | Filtered assignment     |



---

This list should help you dive deeper into each topic and better understand the concepts. If you need detailed answers or code examples for any of these topics, feel free to ask!

In *Pandas*, you can perform a variety of operations that are similar to SQL operations, allowing you to manipulate, filter, and analyze data just like you would in a MySQL database. Below are some common SQL operations and their corresponding Pandas DataFrame operations, along with use cases and examples.

### 1. *SELECT* (Retrieve data from a DataFrame)
   *SQL*: SELECT * FROM table WHERE condition;  
   *Pandas*: Use .loc[] or .query() to select specific rows/columns.

   #### Example:
   python
   import pandas as pd

   # Sample DataFrame
   data = {
       'id': [1, 2, 3, 4],
       'name': ['Alice', 'Bob', 'Charlie', 'David'],
       'age': [25, 30, 35, 40],
   }
   df = pd.DataFrame(data)

   # SELECT * WHERE age > 30
   result = df[df['age'] > 30]
   print(result)
   

   *Output:*
   
      id     name  age
   2   3  Charlie   35
   3   4    David   40
   

### 2. *WHERE* (Filter data based on conditions)
   *SQL*: SELECT * FROM table WHERE condition;  
   *Pandas*: Use boolean indexing or .query() to filter rows.

   #### Example:
   python
   # Filter rows where age is greater than 30
   result = df[df['age'] > 30]
   print(result)
   

   *Output:*
   
      id     name  age
   2   3  Charlie   35
   3   4    David   40
   

### 3. *INSERT* (Add rows to the DataFrame)
   *SQL*: INSERT INTO table VALUES (...);  
   *Pandas*: Use .append() or pd.concat() to add new rows.

   #### Example:
   python
   # Insert a new row to the DataFrame
   new_data = {'id': 5, 'name': 'Eve', 'age': 45}
   df = df.append(new_data, ignore_index=True)
   print(df)
   

   *Output:*
   
      id     name  age
   0   1    Alice   25
   1   2      Bob   30
   2   3  Charlie   35
   3   4    David   40
   4   5      Eve   45
   

### 4. *UPDATE* (Modify existing data)
   *SQL*: UPDATE table SET column = value WHERE condition;  
   *Pandas*: Directly modify the DataFrame using indexing.

   #### Example:
   python
   # Update age for 'Alice' to 28
   df.loc[df['name'] == 'Alice', 'age'] = 28
   print(df)
   

   *Output:*
   
      id     name  age
   0   1    Alice   28
   1   2      Bob   30
   2   3  Charlie   35
   3   4    David   40
   4   5      Eve   45
   

### 5. *DELETE* (Remove rows from the DataFrame)
   *SQL*: DELETE FROM table WHERE condition;  
   *Pandas*: Use .drop() to remove rows based on a condition.

   #### Example:
   python
   # Delete rows where age is greater than 40
   df = df[df['age'] <= 40]
   print(df)
   

   *Output:*
   
      id     name  age
   0   1    Alice   28
   1   2      Bob   30
   2   3  Charlie   35
   3   4    David   40
   

### 6. *JOIN* (Combine DataFrames based on a common column)
   *SQL*: SELECT * FROM table1 INNER JOIN table2 ON table1.id = table2.id;  
   *Pandas*: Use .merge() to perform inner, left, right, or outer joins.

   #### Example:
   python
   # DataFrames to join
   df1 = pd.DataFrame({'id': [1, 2, 3, 4], 'name': ['Alice', 'Bob', 'Charlie', 'David']})
   df2 = pd.DataFrame({'id': [1, 2, 3], 'age': [25, 30, 35]})

   # Perform inner join
   merged_df = pd.merge(df1, df2, on='id', how='inner')
   print(merged_df)
   

   *Output:*
   
      id     name  age
   0   1    Alice   25
   1   2      Bob   30
   2   3  Charlie   35
   

### 7. *GROUP BY* (Group data and perform aggregations)
   *SQL*: SELECT column, COUNT(*) FROM table GROUP BY column;  
   *Pandas*: Use .groupby() to group by a column and apply aggregate functions.

   #### Example:
   python
   # Sample DataFrame with departments
   df = pd.DataFrame({'department': ['HR', 'Sales', 'HR', 'Sales', 'HR'],
                      'employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve']})

   # Group by department and count the number of employees
   result = df.groupby('department')['employee'].count()
   print(result)
   

   *Output:*
   
   department
   HR       3
   Sales    2
   Name: employee, dtype: int64
   

### 8. *ORDER BY* (Sort data by a column)
   *SQL*: SELECT * FROM table ORDER BY column DESC;  
   *Pandas*: Use .sort_values() to sort the DataFrame by one or more columns.

   #### Example:
   python
   # Sort the DataFrame by age in descending order
   sorted_df = df.sort_values(by='age', ascending=False)
   print(sorted_df)
   

   *Output:*
   
      id     name  age
   3   4    David   40
   2   3  Charlie   35
   1   2      Bob   30
   0   1    Alice   28
   

### 9. *HAVING* (Filter data after a GROUP BY operation)
   *SQL*: SELECT department, COUNT(*) FROM table GROUP BY department HAVING COUNT(*) > 1;  
   *Pandas*: After using .groupby(), apply filtering on the result.

   #### Example:
   python
   # Count employees in each department and filter where count > 1
   result = df.groupby('department')['employee'].count()
   result = result[result > 1]
   print(result)
   

   *Output:*
   
   department
   HR       3
   Sales    2
   Name: employee, dtype: int64
   

### 10. *DISTINCT* (Get unique values)
   *SQL*: SELECT DISTINCT column FROM table;  
   *Pandas*: Use .unique() or .drop_duplicates() to get unique values.

   #### Example:
   python
   # Get distinct departments
   distinct_departments = df['department'].unique()
   print(distinct_departments)
   

   *Output:*
   
   ['HR' 'Sales']
   

### 11. *LIMIT* (Limit the number of rows returned)
   *SQL*: SELECT * FROM table LIMIT 3;  
   *Pandas*: Use .head() to return the first N rows.

   #### Example:
   python
   # Get the first 3 rows
   top_3 = df.head(3)
   print(top_3)
   

   *Output:*
   
      id     name  age
   0   1    Alice   28
   1   2      Bob   30
   2   3  Charlie   35
   

### Summary of SQL Operations in Pandas:
- *SELECT*: Use indexing or .query()
- *WHERE*: Use boolean indexing
- *INSERT*: Use .append() or pd.concat()
- *UPDATE*: Modify values directly using .loc[]
- *DELETE*: Use .drop() or filtering
- *JOIN*: Use .merge()
- *GROUP BY*: Use .groupby()
- *ORDER BY*: Use .sort_values()
- *HAVING*: Apply filtering after .groupby()
- *DISTINCT*: Use .unique() or .drop_duplicates()
- *LIMIT*: Use .head()

These are some common SQL-like operations you can perform on a Pandas DataFrame. Pandas is very powerful for data manipulation and analysis, and it allows you to carry out SQL-style operations efficiently.


========================================================================================================================================

An e-commerce company wants to *track customer behavior* (orders, browsing, logins, support interactions) from multiple sources to better understand buying patterns, improve marketing campaigns, and enhance customer support. They need a robust data pipeline that collects, cleans, transforms, and stores customer data in a MySQL database for downstream analytics and reporting.

---

### Pipeline Overview & Step-by-Step Process:

#### 1. *Data Ingestion*

* *Sources:* Web logs (customer clicks, page views), Order Management System (orders, returns), Customer Support tickets, CRM data.
* Data engineer sets up batch jobs (or streaming pipelines) to load raw data into *staging tables* in MySQL.
* Raw data may be JSON, CSV, or API responses.

---

#### 2. *Data Validation & Cleaning*

* Remove duplicates, nulls, and invalid records.
* Standardize data formats: dates, phone numbers, email addresses.
* Example: Correct inconsistent date formats from different sources.

---

#### 3. *Data Enrichment & Transformation*

* *Join customer events*: Link orders, product views, and support tickets by customer_id.
* *Sessionization*: Group clicks and views into browsing sessions using session IDs or time windows.
* *Customer segmentation*: Assign customers into categories (e.g., new, returning, high-value) based on purchase frequency and amount.
* *Calculate derived metrics:*

  * Total revenue per customer
  * Average order value
  * Days since last purchase
  * Customer lifetime value (LTV) estimate

---

#### 4. *Advanced Transformations*

* *Churn Prediction Flag:*

  * Calculate inactivity period; if no purchase or login in last 60 days, flag as potential churn.

* *Behavioral Scoring:*

  * Score customers based on browsing behavior and purchase history to prioritize marketing outreach.

* *Data Aggregations:*

  * Daily active users (DAU)
  * Weekly/monthly revenue by customer segment

Example transformation SQL snippet:

sql
-- Calculate total revenue and orders per customer
INSERT INTO customer_summary (customer_id, total_orders, total_revenue, avg_order_value)
SELECT c.customer_id,
       COUNT(o.order_id) AS total_orders,
       SUM(o.order_amount) AS total_revenue,
       AVG(o.order_amount) AS avg_order_value
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id;


---

#### 5. *Data Storage & Optimization*

* Store transformed data in *analytics-ready tables* with appropriate indexes on customer_id, segment, and last_purchase_date.
* Partition large tables by date or customer segment for faster querying.

---

#### 6. *Orchestration & Automation*

* Schedule ETL workflows with Apache Airflow or cron to run daily/hourly.
* Monitor pipeline health with alerts on failures or delays.

---

#### 7. *Data Access & Reporting*

* BI tools and data analysts use these tables to build dashboards showing:

  * Customer purchase trends
  * Marketing campaign effectiveness
  * Customer churn and retention metrics

---

## Roles & Responsibilities:

| Role                | Responsibilities                                                                                                                                   |
| ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| *Data Engineer*   | Design, build, and maintain data pipelines; write ETL scripts; ensure data quality; optimize MySQL queries; automate workflows; monitor pipelines. |
| *Data Analyst*    | Query data to generate insights; build reports and dashboards; define metrics and KPIs.                                                            |
| *Data Scientist*  | Use transformed data for predictive modeling (churn, segmentation); collaborate with engineers for feature engineering.                            |
| *Product Manager* | Define business requirements and data needs for customer analytics.                                                                                |
| *DevOps Engineer* | Manage infrastructure, automate deployment of ETL jobs, ensure scalability and availability of databases.                                          |

---

### Summary:

* The pipeline collects raw customer activity data from multiple sources.
* It cleans, validates, and enriches data with behavioral and transactional insights.
* Multiple complex transformations generate business metrics and customer segments.
* Automated ETL ensures fresh, accurate data is always available in MySQL.
* Enables marketing, sales, and support teams to make data-driven decisions.

### Pipeline Steps with Queries and Transformations:

#### 1. *Data Ingestion*

Load raw customer logs into a staging table:

sql
LOAD DATA INFILE 'customer_logs.csv' 
INTO TABLE staging_customer_logs 
FIELDS TERMINATED BY ',' ENCLOSED BY '"' 
LINES TERMINATED BY '\n';


---

#### 2. *Data Validation & Cleaning*

Remove records with missing critical fields and clean phone numbers:

sql
DELETE FROM staging_customer_logs 
WHERE customer_id IS NULL OR event_timestamp IS NULL;

UPDATE staging_customer_logs 
SET phone = REGEXP_REPLACE(phone, '[^0-9]', '') 
WHERE phone IS NOT NULL;


---

#### 3. *Data Enrichment & Basic Transformation*

Join multiple source tables to build a unified customer activity table:

sql
INSERT INTO customer_activity (customer_id, total_orders, last_login, support_calls)
SELECT c.customer_id,
       COUNT(o.order_id) AS total_orders,
       MAX(l.login_time) AS last_login,
       COUNT(s.ticket_id) AS support_calls
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
LEFT JOIN logins l ON c.customer_id = l.customer_id
LEFT JOIN support_tickets s ON c.customer_id = s.customer_id
GROUP BY c.customer_id;


---

#### 4. *Advanced Transformations*

Calculate customer revenue and average order value:

sql
INSERT INTO customer_summary (customer_id, total_orders, total_revenue, avg_order_value)
SELECT c.customer_id,
       COUNT(o.order_id) AS total_orders,
       SUM(o.order_amount) AS total_revenue,
       AVG(o.order_amount) AS avg_order_value
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id;


Flag customers likely to churn (no purchase in last 60 days):

sql
UPDATE customer_summary
SET churn_flag = CASE 
                   WHEN DATEDIFF(CURDATE(), last_purchase_date) > 60 THEN 1 
                   ELSE 0 
                 END;


---

#### 5. *Indexing for Performance*

Create index on customer ID to speed up queries:

sql
CREATE INDEX idx_customer_id ON customer_activity(customer_id);
CREATE INDEX idx_last_purchase ON customer_summary(last_purchase_date);


---

### Roles & Responsibilities:

| Role                | Responsibilities                                                                                                                           |
| ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| *Data Engineer*   | Build ETL pipelines, write SQL for data cleaning and transformation, optimize MySQL performance, automate workflows, monitor data quality. |
| *Data Analyst*    | Analyze customer data, build dashboards and reports, define KPIs.                                                                          |
| *Data Scientist*  | Develop models for customer segmentation and churn prediction, work on feature engineering.                                                |
| *Product Manager* | Define business requirements and ensure alignment with data strategy.                                                                      |
| *DevOps Engineer* | Manage database infrastructure and ETL automation tools.                                                                                   |

---

### Summary

This pipeline provides clean, enriched, and transformed customer data for analytics teams, allowing marketing and sales to tailor strategies based on accurate insights like customer behavior, revenue, and churn risk. Automation ensures data freshness and reliability for decision making.